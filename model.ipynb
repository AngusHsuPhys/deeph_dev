{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PairTensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union, Tuple\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCGConv\u001b[39;00m(MessagePassing):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, channels: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]], dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      7\u001b[0m                  aggr: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m, normalization: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m                  bias: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, if_exp: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28msuper\u001b[39m(CGConv, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(aggr\u001b[38;5;241m=\u001b[39maggr, flow\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mCGConv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNorm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn\u001b[38;5;241m.\u001b[39mreset_parameters()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Union[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[43mPairTensor\u001b[49m], edge_index: Adj,\n\u001b[1;32m     46\u001b[0m             edge_attr: OptTensor, batch, distance, size: Size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PairTensor' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from typing import Union, Tuple\n",
    "import torch\n",
    "\n",
    "class CGConv(MessagePassing):\n",
    "    def __init__(self, channels: Union[int, Tuple[int, int]], dim: int = 0,\n",
    "                 aggr: str = 'add', normalization: str = None,\n",
    "                 bias: bool = True, if_exp: bool = False, **kwargs):\n",
    "        super(CGConv, self).__init__(aggr=aggr, flow=\"source_to_target\", **kwargs)\n",
    "        self.channels = channels\n",
    "        self.dim = dim\n",
    "        self.normalization = normalization\n",
    "        self.if_exp = if_exp\n",
    "\n",
    "        if isinstance(channels, int):\n",
    "            channels = (channels, channels)\n",
    "\n",
    "        self.lin_f = nn.Linear(sum(channels) + dim, channels[1], bias=bias)\n",
    "        self.lin_s = nn.Linear(sum(channels) + dim, channels[1], bias=bias)\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            self.bn = nn.BatchNorm1d(channels[1], track_running_stats=True)\n",
    "        elif self.normalization == 'LayerNorm':\n",
    "            self.ln = LayerNorm(channels[1])\n",
    "        elif self.normalization == 'PairNorm':\n",
    "            self.pn = PairNorm(channels[1])\n",
    "        elif self.normalization == 'InstanceNorm':\n",
    "            self.instance_norm = InstanceNorm(channels[1])\n",
    "        elif self.normalization == 'GraphNorm':\n",
    "            self.gn = GraphNorm(channels[1])\n",
    "        elif self.normalization == 'DiffGroupNorm':\n",
    "            self.group_norm = DiffGroupNorm(channels[1], 128)\n",
    "        elif self.normalization is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Unknown normalization function: {}'.format(normalization))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_f.reset_parameters()\n",
    "        self.lin_s.reset_parameters()\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            self.bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Union[torch.Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor, batch, distance, size: Size = None) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: PairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, distance=distance, size=size)\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            out = self.bn(out)\n",
    "        elif self.normalization == 'LayerNorm':\n",
    "            out = self.ln(out, batch)\n",
    "        elif self.normalization == 'PairNorm':\n",
    "            out = self.pn(out, batch)\n",
    "        elif self.normalization == 'InstanceNorm':\n",
    "            out = self.instance_norm(out, batch)\n",
    "        elif self.normalization == 'GraphNorm':\n",
    "            out = self.gn(out, batch)\n",
    "        elif self.normalization == 'DiffGroupNorm':\n",
    "            out = self.group_norm(out)\n",
    "        out += x[1]\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr: OptTensor, distance) -> torch.Tensor:\n",
    "        z = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "        out = self.lin_f(z).sigmoid() * F.softplus(self.lin_s(z))\n",
    "        if self.if_exp:\n",
    "            sigma = 3\n",
    "            n = 2\n",
    "            out = out * torch.exp(-distance ** n / sigma ** n / 2).view(-1, 1)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, dim={})'.format(self.__class__.__name__, self.channels, self.dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMPLayer\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_atom_fea_len, in_edge_fea_len, out_edge_fea_len, if_exp, if_edge_update, normalization,\n\u001b[1;32m      3\u001b[0m                  atom_update_net, gauss_stop, output_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MPLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MPLayer(nn.Module):\n",
    "    def __init__(self, in_atom_fea_len, in_edge_fea_len, out_edge_fea_len, if_exp, if_edge_update, normalization,\n",
    "                 atom_update_net, gauss_stop, output_layer=False):\n",
    "        super(MPLayer, self).__init__()\n",
    "        if atom_update_net == 'CGConv':\n",
    "            self.cgconv = CGConv(channels=in_atom_fea_len,\n",
    "                                 dim=in_edge_fea_len,\n",
    "                                 aggr='add',\n",
    "                                 normalization=normalization,\n",
    "                                 if_exp=if_exp)\n",
    "\n",
    "        self.if_edge_update = if_edge_update\n",
    "        self.atom_update_net = atom_update_net\n",
    "        if if_edge_update:\n",
    "            if output_layer:\n",
    "                self.e_lin = nn.Sequential(nn.Linear(in_edge_fea_len + in_atom_fea_len * 2, 128),\n",
    "                                           nn.SiLU(),\n",
    "                                           nn.Linear(128, out_edge_fea_len),\n",
    "                                           )\n",
    "            else:\n",
    "                self.e_lin = nn.Sequential(nn.Linear(in_edge_fea_len + in_atom_fea_len * 2, 128),\n",
    "                                           nn.SiLU(),\n",
    "                                           nn.Linear(128, out_edge_fea_len),\n",
    "                                           nn.SiLU(),\n",
    "                                           )\n",
    "\n",
    "    def forward(self, atom_fea, edge_idx, edge_fea, batch, distance, edge_vec):\n",
    "        if self.atom_update_net == 'PAINN':\n",
    "            atom_fea = self.cgconv(atom_fea, edge_idx, edge_fea, batch, edge_vec)\n",
    "            atom_fea_s = atom_fea.node_fea_s\n",
    "        else:\n",
    "            atom_fea = self.cgconv(atom_fea, edge_idx, edge_fea, batch, distance)\n",
    "            atom_fea_s = atom_fea\n",
    "        if self.if_edge_update:\n",
    "            row, col = edge_idx\n",
    "            edge_fea = self.e_lin(torch.cat([atom_fea_s[row], atom_fea_s[col], edge_fea], dim=-1))\n",
    "            return atom_fea, edge_fea\n",
    "        else:\n",
    "            return atom_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minideeph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
