{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union, Tuple\n",
    "from math import ceil, sqrt\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import package\n",
    "from torch.nn import MSELoss, L1Loss, SmoothL1Loss\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.norm import LayerNorm, PairNorm, InstanceNorm\n",
    "from torch_geometric.typing import PairTensor, Adj, OptTensor, Size\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.models.dimenet import BesselBasisLayer\n",
    "from torch_scatter import scatter_add, scatter\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from deeph.data import HData\n",
    "\n",
    "from deeph.from_se3_transformer import SphericalHarmonics\n",
    "from deeph.from_schnetpack import GaussianBasis\n",
    "from deeph.from_PyG_future import GraphNorm, DiffGroupNorm\n",
    "from deeph.from_HermNet import RBF, cosine_cutoff, ShiftedSoftplus, _eps\n",
    "from inspect import signature\n",
    "\n",
    "from deeph.utils import LossRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGConv(MessagePassing):\n",
    "    def __init__(self, channels: Union[int, Tuple[int, int]], dim: int = 0,\n",
    "                 aggr: str = 'add', normalization: str = None,\n",
    "                 bias: bool = True, if_exp: bool = False, **kwargs):\n",
    "        super(CGConv, self).__init__(aggr=aggr, flow=\"source_to_target\", **kwargs)\n",
    "        self.channels = channels\n",
    "        self.dim = dim\n",
    "        self.normalization = normalization\n",
    "        self.if_exp = if_exp\n",
    "\n",
    "        if isinstance(channels, int):\n",
    "            channels = (channels, channels)\n",
    "\n",
    "        self.lin_f = nn.Linear(sum(channels) + dim, channels[1], bias=bias)\n",
    "        self.lin_s = nn.Linear(sum(channels) + dim, channels[1], bias=bias)\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            self.bn = nn.BatchNorm1d(channels[1], track_running_stats=True)\n",
    "        elif self.normalization == 'LayerNorm':\n",
    "            self.ln = LayerNorm(channels[1])\n",
    "        elif self.normalization == 'PairNorm':\n",
    "            self.pn = PairNorm(channels[1])\n",
    "        elif self.normalization == 'InstanceNorm':\n",
    "            self.instance_norm = InstanceNorm(channels[1])\n",
    "        elif self.normalization == 'GraphNorm':\n",
    "            self.gn = GraphNorm(channels[1])\n",
    "        elif self.normalization == 'DiffGroupNorm':\n",
    "            self.group_norm = DiffGroupNorm(channels[1], 128)\n",
    "        elif self.normalization is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Unknown normalization function: {}'.format(normalization))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_f.reset_parameters()\n",
    "        self.lin_s.reset_parameters()\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            self.bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Union[torch.Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor, batch, distance, size: Size = None) -> torch.Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: PairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, distance=distance, size=size)\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            out = self.bn(out)\n",
    "        elif self.normalization == 'LayerNorm':\n",
    "            out = self.ln(out, batch)\n",
    "        elif self.normalization == 'PairNorm':\n",
    "            out = self.pn(out, batch)\n",
    "        elif self.normalization == 'InstanceNorm':\n",
    "            out = self.instance_norm(out, batch)\n",
    "        elif self.normalization == 'GraphNorm':\n",
    "            out = self.gn(out, batch)\n",
    "        elif self.normalization == 'DiffGroupNorm':\n",
    "            out = self.group_norm(out)\n",
    "        out += x[1]\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr: OptTensor, distance) -> torch.Tensor:\n",
    "        z = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "        out = self.lin_f(z).sigmoid() * F.softplus(self.lin_s(z))\n",
    "        if self.if_exp: # Very specific section. The message is scaled exponentially with the distance.\n",
    "            sigma = 3\n",
    "            n = 2\n",
    "            out = out * torch.exp(-distance ** n / sigma ** n / 2).view(-1, 1)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, dim={})'.format(self.__class__.__name__, self.channels, self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPLayer(nn.Module):\n",
    "    def __init__(self, in_atom_fea_len, in_edge_fea_len, out_edge_fea_len, if_exp, if_edge_update, normalization,\n",
    "                 atom_update_net, gauss_stop, output_layer=False):\n",
    "        super(MPLayer, self).__init__()\n",
    "        if atom_update_net == 'CGConv':\n",
    "            self.cgconv = CGConv(channels=in_atom_fea_len,\n",
    "                                 dim=in_edge_fea_len,\n",
    "                                 aggr='add',\n",
    "                                 normalization=normalization,\n",
    "                                 if_exp=if_exp)\n",
    "\n",
    "        self.if_edge_update = if_edge_update\n",
    "        self.atom_update_net = atom_update_net\n",
    "        if if_edge_update:\n",
    "            if output_layer:\n",
    "                self.e_lin = nn.Sequential(nn.Linear(in_edge_fea_len + in_atom_fea_len * 2, 128),\n",
    "                                           nn.SiLU(),\n",
    "                                           nn.Linear(128, out_edge_fea_len),\n",
    "                                           )\n",
    "            else:\n",
    "                self.e_lin = nn.Sequential(nn.Linear(in_edge_fea_len + in_atom_fea_len * 2, 128),\n",
    "                                           nn.SiLU(),\n",
    "                                           nn.Linear(128, out_edge_fea_len),\n",
    "                                           nn.SiLU(),\n",
    "                                           )\n",
    "\n",
    "    def forward(self, atom_fea, edge_idx, edge_fea, batch, distance, edge_vec):\n",
    "        atom_fea = self.cgconv(atom_fea, edge_idx, edge_fea, batch, distance)\n",
    "        atom_fea_s = atom_fea\n",
    "        if self.if_edge_update:\n",
    "            row, col = edge_idx\n",
    "            edge_fea = self.e_lin(torch.cat([atom_fea_s[row], atom_fea_s[col], edge_fea], dim=-1))\n",
    "            return atom_fea, edge_fea\n",
    "        else:\n",
    "            return atom_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCMPLayer(nn.Module):\n",
    "    def __init__(self, in_atom_fea_len, in_edge_fea_len, out_edge_fea_len, num_l,\n",
    "                 normalization: str = None, bias: bool = True, if_exp: bool = False):\n",
    "        super(LCMPLayer, self).__init__()\n",
    "        self.in_atom_fea_len = in_atom_fea_len\n",
    "        self.normalization = normalization\n",
    "        self.if_exp = if_exp\n",
    "\n",
    "        self.lin_f = nn.Linear(in_atom_fea_len * 2 + in_edge_fea_len, in_atom_fea_len, bias=bias)\n",
    "        self.lin_s = nn.Linear(in_atom_fea_len * 2 + in_edge_fea_len, in_atom_fea_len, bias=bias)\n",
    "        self.bn = nn.BatchNorm1d(in_atom_fea_len, track_running_stats=True)\n",
    "\n",
    "        self.e_lin = nn.Sequential(\n",
    "            nn.Linear(in_edge_fea_len + in_atom_fea_len * 2 - num_l ** 2, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, out_edge_fea_len)\n",
    "        )\n",
    "        \n",
    "        self.final_linear = nn.Linear(out_edge_fea_len, 1)  # New linear layer to reduce to a single number\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_f.reset_parameters()\n",
    "        self.lin_s.reset_parameters()\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            self.bn.reset_parameters()\n",
    "        self.final_linear.reset_parameters()\n",
    "\n",
    "    def forward(self, atom_fea, edge_fea, sub_atom_idx, sub_edge_idx, sub_edge_ang, sub_index, distance,\n",
    "                huge_structure, output_final_layer_neuron):\n",
    "        if huge_structure:\n",
    "            sub_graph_batch_num = 8\n",
    "\n",
    "            sub_graph_num = sub_atom_idx.shape[0]\n",
    "            sub_graph_batch_size = ceil(sub_graph_num / sub_graph_batch_num)\n",
    "\n",
    "            num_edge = edge_fea.shape[0]\n",
    "            vf_update = torch.zeros((num_edge * 2, self.in_atom_fea_len)).type(torch.get_default_dtype()).to(atom_fea.device)\n",
    "            for sub_graph_batch_index in range(sub_graph_batch_num):\n",
    "                if sub_graph_batch_index == sub_graph_batch_num - 1:\n",
    "                    sub_graph_idx = slice(sub_graph_batch_size * sub_graph_batch_index, sub_graph_num)\n",
    "                else:\n",
    "                    sub_graph_idx = slice(sub_graph_batch_size * sub_graph_batch_index,\n",
    "                                          sub_graph_batch_size * (sub_graph_batch_index + 1))\n",
    "\n",
    "                sub_atom_idx_batch = sub_atom_idx[sub_graph_idx]\n",
    "                sub_edge_idx_batch = sub_edge_idx[sub_graph_idx]\n",
    "                sub_edge_ang_batch = sub_edge_ang[sub_graph_idx]\n",
    "                sub_index_batch = sub_index[sub_graph_idx]\n",
    "\n",
    "                z = torch.cat([atom_fea[sub_atom_idx_batch][:, 0, :], atom_fea[sub_atom_idx_batch][:, 1, :],\n",
    "                               edge_fea[sub_edge_idx_batch], sub_edge_ang_batch], dim=-1)\n",
    "                out = self.lin_f(z).sigmoid() * F.softplus(self.lin_s(z))\n",
    "\n",
    "                if self.if_exp:\n",
    "                    sigma = 3\n",
    "                    n = 2\n",
    "                    out = out * torch.exp(-distance[sub_edge_idx_batch] ** n / sigma ** n / 2).view(-1, 1)\n",
    "\n",
    "                vf_update += scatter_add(out, sub_index_batch, dim=0, dim_size=num_edge * 2)\n",
    "\n",
    "            if self.normalization == 'BatchNorm':\n",
    "                vf_update = self.bn(vf_update)\n",
    "            vf_update = vf_update.reshape(num_edge, 2, -1)\n",
    "            if output_final_layer_neuron != '':\n",
    "                final_layer_neuron = torch.cat([vf_update[:, 0, :], vf_update[:, 1, :], edge_fea],\n",
    "                                               dim=-1).detach().cpu().numpy()\n",
    "                np.save(os.path.join(output_final_layer_neuron, 'final_layer_neuron.npy'), final_layer_neuron)\n",
    "            out = self.e_lin(torch.cat([vf_update[:, 0, :], vf_update[:, 1, :], edge_fea], dim=-1))\n",
    "\n",
    "            # Aggregate over all edges to produce a single number\n",
    "            out = out.mean(dim=0, keepdim=True)  # Aggregating over num_edge\n",
    "            out = self.final_linear(out)  # Final linear layer to produce a single number\n",
    "            out = out.squeeze(0)\n",
    "            return out\n",
    "\n",
    "        num_edge = edge_fea.shape[0]\n",
    "        z = torch.cat(\n",
    "            [atom_fea[sub_atom_idx][:, 0, :], atom_fea[sub_atom_idx][:, 1, :], edge_fea[sub_edge_idx], sub_edge_ang],\n",
    "            dim=-1)\n",
    "        out = self.lin_f(z).sigmoid() * F.softplus(self.lin_s(z))\n",
    "\n",
    "        if self.if_exp:\n",
    "            sigma = 3\n",
    "            n = 2\n",
    "            out = out * torch.exp(-distance[sub_edge_idx] ** n / sigma ** n / 2).view(-1, 1)\n",
    "\n",
    "        out = scatter_add(out, sub_index, dim=0)\n",
    "        if self.normalization == 'BatchNorm':\n",
    "            out = self.bn(out)\n",
    "        out = out.reshape(num_edge, 2, -1)\n",
    "        if output_final_layer_neuron != '':\n",
    "            final_layer_neuron = torch.cat([out[:, 0, :], out[:, 1, :], edge_fea], dim=-1).detach().cpu().numpy()\n",
    "            np.save(os.path.join(output_final_layer_neuron, 'final_layer_neuron.npy'), final_layer_neuron)\n",
    "        out = self.e_lin(torch.cat([out[:, 0, :], out[:, 1, :], edge_fea], dim=-1))\n",
    "\n",
    "        out = out.mean(dim=0, keepdim=True)  # Aggregating over num_edge\n",
    "        out = self.final_linear(out)  # Final linear layer to produce a single number\n",
    "        \n",
    "        out = out.squeeze(0)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinear(nn.Module):\n",
    "    def __init__(self, num_linear: int, in_fea_len: int, out_fea_len: int, bias: bool = True) -> None:\n",
    "        super(MultipleLinear, self).__init__()\n",
    "        self.num_linear = num_linear\n",
    "        self.out_fea_len = out_fea_len\n",
    "        self.weight = nn.Parameter(torch.Tensor(num_linear, in_fea_len, out_fea_len))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_linear, out_fea_len))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        # self.ln = LayerNorm(num_linear * out_fea_len)\n",
    "        # self.gn = GraphNorm(out_fea_len)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.weight, a=sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, batch_edge: torch.Tensor) -> torch.Tensor:\n",
    "        output = torch.matmul(input, self.weight)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            output += self.bias[:, None, :]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, num_species, in_atom_fea_len, in_edge_fea_len, num_orbital,\n",
    "                 distance_expansion, gauss_stop, if_exp, if_MultipleLinear, if_edge_update, if_lcmp,\n",
    "                 normalization, atom_update_net, separate_onsite,\n",
    "                 trainable_gaussians, type_affine, num_l=5):\n",
    "        super(HGNN, self).__init__()\n",
    "        self.num_species = num_species\n",
    "        self.embed = nn.Embedding(num_species + 5, in_atom_fea_len)\n",
    "\n",
    "        self.dynamic_linear = None\n",
    "\n",
    "        # pair-type aware affine\n",
    "        if type_affine:\n",
    "            self.type_affine = nn.Embedding(\n",
    "                num_species ** 2, 2,\n",
    "                _weight=torch.stack([torch.ones(num_species ** 2), torch.zeros(num_species ** 2)], dim=-1)\n",
    "            )\n",
    "        else:\n",
    "            self.type_affine = None\n",
    "\n",
    "        if if_edge_update or (if_edge_update is False and if_lcmp is False):\n",
    "            distance_expansion_len = in_edge_fea_len\n",
    "        else:\n",
    "            distance_expansion_len = in_edge_fea_len - num_l ** 2\n",
    "        if distance_expansion == 'GaussianBasis':\n",
    "            self.distance_expansion = GaussianBasis(\n",
    "                0.0, gauss_stop, distance_expansion_len, trainable=trainable_gaussians\n",
    "            )\n",
    "\n",
    "        self.if_MultipleLinear = if_MultipleLinear\n",
    "        self.if_edge_update = if_edge_update\n",
    "        self.if_lcmp = if_lcmp\n",
    "        self.atom_update_net = atom_update_net\n",
    "        self.separate_onsite = separate_onsite\n",
    "        if if_lcmp == True:\n",
    "            mp_output_edge_fea_len = in_edge_fea_len - num_l ** 2\n",
    "\n",
    "        if if_edge_update == True:\n",
    "            self.mp1 = MPLayer(in_atom_fea_len, in_edge_fea_len, in_edge_fea_len, if_exp, if_edge_update, normalization,\n",
    "                               atom_update_net, gauss_stop)\n",
    "            self.mp2 = MPLayer(in_atom_fea_len, in_edge_fea_len, in_edge_fea_len, if_exp, if_edge_update, normalization,\n",
    "                               atom_update_net, gauss_stop)\n",
    "            self.mp3 = MPLayer(in_atom_fea_len, in_edge_fea_len, in_edge_fea_len, if_exp, if_edge_update, normalization,\n",
    "                               atom_update_net, gauss_stop)\n",
    "            self.mp4 = MPLayer(in_atom_fea_len, in_edge_fea_len, in_edge_fea_len, if_exp, if_edge_update, normalization,\n",
    "                               atom_update_net, gauss_stop)\n",
    "            self.mp5 = MPLayer(in_atom_fea_len, in_edge_fea_len, mp_output_edge_fea_len, if_exp, if_edge_update,\n",
    "                               normalization, atom_update_net, gauss_stop)\n",
    "\n",
    "        if if_lcmp == True:\n",
    "            if self.if_MultipleLinear == True:\n",
    "                self.lcmp = LCMPLayer(in_atom_fea_len, in_edge_fea_len, 32, num_l, if_exp=if_exp)\n",
    "                self.multiple_linear1 = MultipleLinear(num_orbital, 32, 16)\n",
    "                self.multiple_linear2 = MultipleLinear(num_orbital, 16, 1)\n",
    "            else:\n",
    "                self.lcmp = LCMPLayer(in_atom_fea_len, in_edge_fea_len, num_orbital, num_l, if_exp=if_exp)\n",
    "                self.final_linear = nn.Linear(in_edge_fea_len, 1)\n",
    "\n",
    "        else:\n",
    "            self.mp_output = MPLayer(in_atom_fea_len, in_edge_fea_len, num_orbital, if_exp, if_edge_update=True,\n",
    "                                     normalization=normalization, atom_update_net=atom_update_net,\n",
    "                                     gauss_stop=gauss_stop, output_layer=True)\n",
    "\n",
    "        \n",
    "    def forward(self, atom_attr, edge_idx, edge_attr, batch,\n",
    "                sub_atom_idx=None, sub_edge_idx=None, sub_edge_ang=None, sub_index=None,\n",
    "                huge_structure=False, output_final_layer_neuron=''):\n",
    "        batch_edge = batch[edge_idx[0]]\n",
    "        atom_fea0 = self.embed(atom_attr)\n",
    "        distance = edge_attr[:, 0]\n",
    "        edge_vec = edge_attr[:, 1:4] - edge_attr[:, 4:7]\n",
    "        if self.type_affine is None:\n",
    "            edge_fea0 = self.distance_expansion(distance)\n",
    "        else:\n",
    "            affine_coeff = self.type_affine(self.num_species * atom_attr[edge_idx[0]] + atom_attr[edge_idx[1]])\n",
    "            edge_fea0 = self.distance_expansion(distance * affine_coeff[:, 0] + affine_coeff[:, 1])\n",
    "\n",
    "        if self.if_edge_update == True:\n",
    "            atom_fea, edge_fea = self.mp1(atom_fea0, edge_idx, edge_fea0, batch, distance, edge_vec)\n",
    "            atom_fea, edge_fea = self.mp2(atom_fea, edge_idx, edge_fea, batch, distance, edge_vec)\n",
    "            atom_fea0, edge_fea0 = atom_fea0 + atom_fea, edge_fea0 + edge_fea\n",
    "            atom_fea, edge_fea = self.mp3(atom_fea0, edge_idx, edge_fea0, batch, distance, edge_vec)\n",
    "            atom_fea, edge_fea = self.mp4(atom_fea, edge_idx, edge_fea, batch, distance, edge_vec)\n",
    "            atom_fea0, edge_fea0 = atom_fea0 + atom_fea, edge_fea0 + edge_fea\n",
    "            atom_fea, edge_fea = self.mp5(atom_fea0, edge_idx, edge_fea0, batch, distance, edge_vec)\n",
    "\n",
    "            if self.if_lcmp == True:\n",
    "                atom_fea_s = atom_fea\n",
    "                out = self.lcmp(atom_fea_s, edge_fea, sub_atom_idx, sub_edge_idx, sub_edge_ang, sub_index, distance,\n",
    "                                huge_structure, output_final_layer_neuron)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HData(\n",
    "    raw_data_dir='/home/t.hsu/DeepRFnet/DeepDOS/work_dir/dataset/processed',\n",
    "    graph_dir='/home/t.hsu/DeepRFnet/DeepDOS/work_dir/dataset/graph',\n",
    "    interface='h5',\n",
    "    target='hamiltonian',\n",
    "    dataset_name='Bi_soc',\n",
    "    multiprocessing=0,\n",
    "    radius='-1.0',\n",
    "    max_num_nbr=0,\n",
    "    num_l='5',\n",
    "    max_element='-1',\n",
    "    create_from_DFT='True',\n",
    "    if_lcmp_graph='True',\n",
    "    separate_onsite='False',\n",
    "    new_sp=False,\n",
    "    default_dtype_torch=torch.get_default_dtype(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "from deeph.kernel import DeepHKernel\n",
    "# Initialize the ConfigParser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read('/home/t.hsu/deeph_dev/default.ini')\n",
    "\n",
    "config.read('/home/t.hsu/deeph_dev/train.ini')  # Replace 'config.ini' with your actual file name\n",
    "kernel = DeepHKernel(config)\n",
    "_, _, _, _ = kernel.get_dataset()\n",
    "num_species = len(dataset.info[\"index_to_Z\"])\n",
    "orbital = json.loads(config.get('basic', 'orbital'))\n",
    "num_orbital = len(orbital)\n",
    "spinful = True\n",
    "if_lcmp = True\n",
    "separate_onsite = False\n",
    "if spinful:\n",
    "    out_fea_len = num_orbital * 8\n",
    "else:\n",
    "    out_fea_len = num_orbital\n",
    "print('DeepH', out_fea_len)\n",
    "out_fea_len = 1\n",
    "print('Fermi', out_fea_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(\n",
    "    n_elements=num_species,\n",
    "    num_species=num_species,\n",
    "    in_atom_fea_len=config.getint('network', 'atom_fea_len'),\n",
    "    in_vfeats=config.getint('network', 'atom_fea_len'),\n",
    "    in_edge_fea_len=config.getint('network', 'edge_fea_len'),\n",
    "    in_efeats=config.getint('network', 'edge_fea_len'),\n",
    "    out_edge_fea_len=out_fea_len,\n",
    "    out_efeats=out_fea_len,\n",
    "    num_orbital=out_fea_len,\n",
    "    distance_expansion=config.get('network', 'distance_expansion'),\n",
    "    gauss_stop=config.getfloat('network', 'gauss_stop'),\n",
    "    cutoff=config.getfloat('network', 'gauss_stop'),\n",
    "    if_exp=config.getboolean('network', 'if_exp'),\n",
    "    if_MultipleLinear=config.getboolean('network', 'if_MultipleLinear'),\n",
    "    if_edge_update=config.getboolean('network', 'if_edge_update'),\n",
    "    if_lcmp=if_lcmp,\n",
    "    normalization=config.get('network', 'normalization'),\n",
    "    atom_update_net=config.get('network', 'atom_update_net', fallback='CGConv'),\n",
    "    separate_onsite=separate_onsite,\n",
    "    num_l=config.getint('network', 'num_l'),\n",
    "    trainable_gaussians=config.getboolean('network', 'trainable_gaussians', fallback=False),\n",
    "    type_affine=config.getboolean('network', 'type_affine', fallback=False),\n",
    "    if_fc_out=False,\n",
    ")\n",
    "parameter_list = list(signature(HGNN.__init__).parameters.keys())\n",
    "current_parameter_list = list(model_kwargs.keys())\n",
    "for k in current_parameter_list:\n",
    "    if k not in parameter_list:\n",
    "        model_kwargs.pop(k)\n",
    "if 'num_elements' in parameter_list:\n",
    "    model_kwargs['num_elements'] = config.getint('basic', 'max_element') + 1\n",
    "model = HGNN(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"The model you built has: %d parameters\" % params)\n",
    "\n",
    "# from torchviz import make_dot\n",
    "# dot = make_dot(model, params=dict(model.named_parameters()))\n",
    "# dot.format = 'png'\n",
    "# dot.render('./deeph_dev/model_visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(config.get('basic', 'device') if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(dataset):\n",
    "    spinful = True\n",
    "    target = 'hamiltonian'\n",
    "    num_orbital = kernel.num_orbital\n",
    "    dataset_mask = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        # filename = '/home/t.hsu/DeepRFnet/DeepDOS/work_dir/dataset/raw/{}/openmx.DOS.Gaussian'.format(i)\n",
    "        # aux = np.loadtxt(filename)\n",
    "\n",
    "        # dos = torch.tensor(aux[:,1], dtype=torch.float32)  # Convert to tensor if not already\n",
    "        # dos = dos.view(-1)\n",
    "        Oij_value = data.term_real\n",
    "        if data.term_real is not None:\n",
    "            if_only_rc = False\n",
    "\n",
    "        if spinful:\n",
    "            out_fea_len = num_orbital * 8\n",
    "            # out_fea_len = 999\n",
    "            \n",
    "        mask = torch.zeros(data.edge_attr.shape[0], out_fea_len, dtype=torch.int8)\n",
    "        label = torch.zeros(data.edge_attr.shape[0], out_fea_len, dtype=torch.get_default_dtype())\n",
    "        y = torch.zeros(data.edge_attr.shape[0], 1, dtype=torch.get_default_dtype())\n",
    "\n",
    "        atomic_number_edge_i = kernel.index_to_Z[data.x[data.edge_index[0]]]\n",
    "        atomic_number_edge_j = kernel.index_to_Z[data.x[data.edge_index[1]]]\n",
    "\n",
    "        for index_out, orbital_dict in enumerate(kernel.orbital):\n",
    "            for N_M_str, a_b in orbital_dict.items():\n",
    "                # N_M, a_b means: H_{ia, jb} when the atomic number of atom i is N and the atomic number of atom j is M\n",
    "                condition_atomic_number_i, condition_atomic_number_j = map(lambda x: int(x), N_M_str.split())\n",
    "                condition_orbital_i, condition_orbital_j = a_b\n",
    "\n",
    "                if spinful:\n",
    "                    if target == 'phiVdphi':\n",
    "                        raise NotImplementedError(\"Not yet have support for phiVdphi\")\n",
    "                    else:\n",
    "                        mask[:, 8 * index_out:8 * (index_out + 1)] = torch.where(\n",
    "                            (atomic_number_edge_i == condition_atomic_number_i)\n",
    "                            & (atomic_number_edge_j == condition_atomic_number_j),\n",
    "                            1,\n",
    "                            0\n",
    "                        )[:, None].repeat(1, 8)\n",
    "                else:\n",
    "                    if target == 'phiVdphi':\n",
    "                        mask[:, 3 * index_out:3 * (index_out + 1)] += torch.where(\n",
    "                            (atomic_number_edge_i == condition_atomic_number_i)\n",
    "                            & (atomic_number_edge_j == condition_atomic_number_j),\n",
    "                            1,\n",
    "                            0\n",
    "                        )[:, None].repeat(1, 3)\n",
    "                    else:\n",
    "                        mask[:, index_out] += torch.where(\n",
    "                            (atomic_number_edge_i == condition_atomic_number_i)\n",
    "                            & (atomic_number_edge_j == condition_atomic_number_j),\n",
    "                            1,\n",
    "                            0\n",
    "                        )\n",
    "\n",
    "                if if_only_rc == False:\n",
    "                    if spinful:\n",
    "                        if target == 'phiVdphi':\n",
    "                            raise NotImplementedError\n",
    "                        else:\n",
    "                            label[:, 8 * index_out:8 * (index_out + 1)] = torch.where(\n",
    "                                (atomic_number_edge_i == condition_atomic_number_i)\n",
    "                                & (atomic_number_edge_j == condition_atomic_number_j),\n",
    "                                Oij_value[:, condition_orbital_i, condition_orbital_j].t(),\n",
    "                                torch.zeros(8, data.edge_attr.shape[0], dtype=torch.get_default_dtype())\n",
    "                            ).t()\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        if target == 'phiVdphi':\n",
    "                            label[:, 3 * index_out:3 * (index_out + 1)] = torch.where(\n",
    "                                (atomic_number_edge_i == condition_atomic_number_i)\n",
    "                                & (atomic_number_edge_j == condition_atomic_number_j),\n",
    "                                Oij_value[:, condition_orbital_i, condition_orbital_j].t(),\n",
    "                                torch.zeros(3, data.edge_attr.shape[0], dtype=torch.get_default_dtype())\n",
    "                            ).t()\n",
    "                        else:\n",
    "                            label[:, index_out] += torch.where(\n",
    "                                (atomic_number_edge_i == condition_atomic_number_i)\n",
    "                                & (atomic_number_edge_j == condition_atomic_number_j),\n",
    "                                Oij_value[:, condition_orbital_i, condition_orbital_j],\n",
    "                                torch.zeros(data.edge_attr.shape[0], dtype=torch.get_default_dtype())\n",
    "                            )\n",
    "        assert len(torch.where((mask != 1) & (mask != 0))[0]) == 0\n",
    "        mask = mask.bool()\n",
    "        data.mask = mask\n",
    "        del data.term_mask\n",
    "        if if_only_rc == False:\n",
    "            data.label = label\n",
    "            data.y = y\n",
    "            if target == 'hamiltonian' or target == 'density_matrix':\n",
    "                del data.term_real\n",
    "        dataset_mask.append(data)\n",
    "    return dataset_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The 'data' object was created by an older version of PyG. If this error occurred while loading an already existing dataset, remove the 'processed/' directory in the dataset's root folder and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_size)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m make_mask(dataset)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Iterating over the 81 graph.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for i in range(len(dataset)-1):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     filename = '/home/t.hsu/DeepRFnet/DeepDOS/work_dir/dataset/raw/{}/openmx.DOS.Gaussian'.format(i)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     # aux2 = dataset[i].label[:,:len(dos)]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     dataset[i].y = dos.expand((dataset[i].label.shape[0]), -1)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/dataset.py:289\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 289\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:111\u001b[0m, in \u001b[0;36mInMemoryDataset.get\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx])\n\u001b[0;32m--> 111\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mseparate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(data)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/separate.py:32\u001b[0m, in \u001b[0;36mseparate\u001b[0;34m(cls, batch, idx, slice_dict, inc_dict, decrement)\u001b[0m\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\u001b[38;5;241m.\u001b[39mstores_as(batch)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Iterate over each storage object and recursively separate its attributes:\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_store, data_store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstores\u001b[49m, data\u001b[38;5;241m.\u001b[39mstores):\n\u001b[1;32m     33\u001b[0m     key \u001b[38;5;241m=\u001b[39m batch_store\u001b[38;5;241m.\u001b[39m_key\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Heterogeneous:\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/data.py:625\u001b[0m, in \u001b[0;36mData.stores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstores\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseStorage]:\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m]\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/data.py:554\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m--> 554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, key)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The 'data' object was created by an older version of PyG. If this error occurred while loading an already existing dataset, remove the 'processed/' directory in the dataset's root folder and try again."
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "print(dataset_size)\n",
    "print(dataset[0])\n",
    "dataset = make_mask(dataset)\n",
    "# Iterating over the 81 graph.\n",
    "# for i in range(len(dataset)-1):\n",
    "#     filename = '/home/t.hsu/DeepRFnet/DeepDOS/work_dir/dataset/raw/{}/openmx.DOS.Gaussian'.format(i)\n",
    "#     aux = np.loadtxt(filename)\n",
    "\n",
    "#     # Extract the first and second columns\n",
    "#     energy = aux[:, 0]\n",
    "#     dos = torch.tensor(aux[:, 1],dtype=torch.get_default_dtype())\n",
    "\n",
    "#     # aux2 = dataset[i].label[:,:len(dos)]\n",
    "#     dataset[i].y = dos.expand((dataset[i].label.shape[0]), -1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The 'data' object was created by an older version of PyG. If this error occurred while loading an already existing dataset, remove the 'processed/' directory in the dataset's root folder and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/dataset.py:294\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/dataset.py:342\u001b[0m, in \u001b[0;36mDataset.index_select\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly slices (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m), list, tuples, torch.tensor and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray of dtype long or bool are valid indices (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(idx)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 342\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m dataset\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;241m=\u001b[39m indices\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/copy.py:92\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     90\u001b[0m reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:311\u001b[0m, in \u001b[0;36mInMemoryDataset.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    310\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Data) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39m__inc__(key, data[key]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    313\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data[key]\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/data.py:158\u001b[0m, in \u001b[0;36mBaseData.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns :obj:`True` if the attribute :obj:`key` is present in the\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    data.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/data.py:146\u001b[0m, in \u001b[0;36mBaseData.keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of all graph attribute names.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstores\u001b[49m:\n\u001b[1;32m    147\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(store\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(out))\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/data.py:625\u001b[0m, in \u001b[0;36mData.stores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstores\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseStorage]:\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m]\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_test/lib/python3.10/site-packages/torch_geometric/data/data.py:554\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m--> 554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store, key)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The 'data' object was created by an older version of PyG. If this error occurred while loading an already existing dataset, remove the 'processed/' directory in the dataset's root folder and try again."
     ]
    }
   ],
   "source": [
    "dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# Path to the parent directory containing the 80 directories\n",
    "parent_directory = '/home/t.hsu/example2/work_dir/dataset/processed'\n",
    "\n",
    "# Initialize a list to store the fermi_level values\n",
    "fermi_levels = []\n",
    "\n",
    "# Loop through each directory\n",
    "for i, directory in enumerate(os.listdir(parent_directory)):\n",
    "    print(i)\n",
    "    dir_path = os.path.join(parent_directory, directory)\n",
    "\n",
    "    # Check if the current path is a directory\n",
    "    if os.path.isdir(dir_path):\n",
    "        # Path to the info.json file\n",
    "        info_path = os.path.join(dir_path, 'info.json')\n",
    "        \n",
    "        # Check if the info.json file exists\n",
    "        if os.path.isfile(info_path):\n",
    "            with open(info_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                # Extract the fermi_level and store it in the list\n",
    "                fermi_level = data.get('fermi_level')\n",
    "                # if fermi_level is not None:\n",
    "                    # fermi_level_tensor= torch.tensor([fermi_level], dtype=torch.get_default_dtype())\n",
    "                    # dataset[i].y = fermi_level_tensor.expand((dataset[i].label.shape[0]), -1)\n",
    "                    \n",
    "                dataset[i].y = torch.tensor(fermi_level, dtype=torch.get_default_dtype())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = int(test_ratio * dataset_size)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_sampler = SubsetRandomSampler(indices[:train_size])\n",
    "val_sampler = SubsetRandomSampler(indices[train_size:train_size + val_size])\n",
    "test_sampler = SubsetRandomSampler(indices[train_size + val_size:train_size + val_size + test_size])\n",
    "from deeph.graph import Collater\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=1,\n",
    "                            shuffle=False, sampler=train_sampler,\n",
    "                            collate_fn=Collater(True))\n",
    "val_loader = DataLoader(dataset, batch_size=1,\n",
    "                        shuffle=False, sampler=val_sampler,\n",
    "                        collate_fn=Collater(True))\n",
    "test_loader = DataLoader(dataset, batch_size=1,\n",
    "                            shuffle=False, sampler=test_sampler,\n",
    "                            collate_fn=Collater(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "weight_decay = 0\n",
    "criterion = nn.SmoothL1Loss()  # Example loss function\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.SGD(model_parameters, lr=learning_rate, weight_decay=weight_decay)\n",
    "# optimizer = optim.Adam(model_parameters, lr=learning_rate, betas=(0.9, 0.999))\n",
    "epochs = np.arange(1, 101)\n",
    "losses = [] \n",
    "best_model_path = '/home/t.hsu/deeph_dev/best_model.pth'\n",
    "best_loss = float('inf')\n",
    "\n",
    "for e in epochs:\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    for step, batch_tuple in enumerate(train_loader):\n",
    "        if if_lcmp:\n",
    "            batch, subgraph = batch_tuple\n",
    "            sub_atom_idx, sub_edge_idx, sub_edge_ang, sub_index = subgraph\n",
    "            output = model(\n",
    "                batch.x.to(device),\n",
    "                batch.edge_index.to(device),\n",
    "                batch.edge_attr.to(device),\n",
    "                batch.batch.to(device),\n",
    "                sub_atom_idx.to(device),\n",
    "                sub_edge_idx.to(device),\n",
    "                sub_edge_ang.to(device),\n",
    "                sub_index.to(device)\n",
    "                    )\n",
    "            target_labels = batch.y.to(device)\n",
    "            loss = criterion(output, target_labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    losses.append(avg_epoch_loss)\n",
    "    if avg_epoch_loss < best_loss:\n",
    "        best_loss = avg_epoch_loss  # Update the best loss\n",
    "        torch.save(model.state_dict(), best_model_path)  # Save the model with the best loss\n",
    "        print(f\"Epoch {e+1}: New best model saved with loss {best_loss:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {e+1}: Average Loss = {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete. Best model saved as 'best_model.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.4110844332414367,\n",
       " 3.061492654165098,\n",
       " 2.6595832311625904,\n",
       " 2.212671786546707,\n",
       " 1.7193157027165096,\n",
       " 1.1569318324327469,\n",
       " 0.5185137316584587,\n",
       " 0.1544153089635074,\n",
       " 0.07978701124860284,\n",
       " 0.06795243071792356,\n",
       " 0.06613122556306432,\n",
       " 0.06573804147237183,\n",
       " 0.06565469844768519,\n",
       " 0.06563551853418421,\n",
       " 0.06560187033113844,\n",
       " 0.06565236104988988,\n",
       " 0.0656367095798019,\n",
       " 0.06560797065330111,\n",
       " 0.06564164935796708,\n",
       " 0.06563622892568806,\n",
       " 0.0656369825632505,\n",
       " 0.06561879635025036,\n",
       " 0.06563084984952638,\n",
       " 0.06562934297386036,\n",
       " 0.06563222496166077,\n",
       " 0.06563019489410789,\n",
       " 0.06563086972080139,\n",
       " 0.06563231767177591,\n",
       " 0.06563609866215891,\n",
       " 0.06558790401689052,\n",
       " 0.06564654685808158,\n",
       " 0.06559608701920716,\n",
       " 0.06561833312040773,\n",
       " 0.06563427360527936,\n",
       " 0.06563517621718813,\n",
       " 0.06563363411519656,\n",
       " 0.06562426321046406,\n",
       " 0.06559574571793962,\n",
       " 0.06560851428746162,\n",
       " 0.06562549996422362,\n",
       " 0.06562218676555294,\n",
       " 0.06563487948978579,\n",
       " 0.06558684834239929,\n",
       " 0.06558912470235612,\n",
       " 0.06563024244347797,\n",
       " 0.06561973377058017,\n",
       " 0.06563169530820367,\n",
       " 0.06562548621616315,\n",
       " 0.06561384741829339,\n",
       " 0.06564033484719071,\n",
       " 0.06562121374367298,\n",
       " 0.0656306309534364,\n",
       " 0.06564299985153473,\n",
       " 0.06561700655173534,\n",
       " 0.06563281306402757,\n",
       " 0.06561071490252897,\n",
       " 0.06563508999243577,\n",
       " 0.06559674697473916,\n",
       " 0.06562929291908522,\n",
       " 0.06563237815135044,\n",
       " 0.0656006616266372,\n",
       " 0.0656389627910657,\n",
       " 0.06562665275123909,\n",
       " 0.06563162442367165,\n",
       " 0.06560181939022058,\n",
       " 0.0656234243750949,\n",
       " 0.06563167447362635,\n",
       " 0.06560205448977759,\n",
       " 0.0656369409204783,\n",
       " 0.0656315690058662,\n",
       " 0.06562790778576044,\n",
       " 0.06563043981306353,\n",
       " 0.06559638801464611,\n",
       " 0.06559377597127873,\n",
       " 0.06562392288669254,\n",
       " 0.06558912273422379,\n",
       " 0.06560162474884201,\n",
       " 0.06562027018619195,\n",
       " 0.06564614329527352,\n",
       " 0.06563213349784291,\n",
       " 0.06558139955668037,\n",
       " 0.06563814447760308,\n",
       " 0.06563120244204927,\n",
       " 0.06563092724399174,\n",
       " 0.0656319142034955,\n",
       " 0.06558192791118482,\n",
       " 0.06559494996930997,\n",
       " 0.06565432515789855,\n",
       " 0.06562503771746127,\n",
       " 0.06565062897743701,\n",
       " 0.06563949353848386,\n",
       " 0.06561373019896166,\n",
       " 0.06562478007521595,\n",
       " 0.06563503620215332,\n",
       " 0.06563625457726611,\n",
       " 0.06563298354114977,\n",
       " 0.06560200760800032,\n",
       " 0.06561892730255714,\n",
       " 0.06564324259254779,\n",
       " 0.06563068306719917]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00557637], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.cpu().detach().numpy()-target_labels.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs,losses)\n",
    "\n",
    "plt.title('Training Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Ticks and limits\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlim([1, 101])\n",
    "plt.ylim([min(losses) - 0.0001, max(losses) + 0.0001])\n",
    "\n",
    "# Adding legend\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig('training_loss_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "difference = []\n",
    "with torch.no_grad():\n",
    "    for step, batch_tuple in enumerate(train_loader):\n",
    "        if if_lcmp:\n",
    "            batch, subgraph = batch_tuple\n",
    "            sub_atom_idx, sub_edge_idx, sub_edge_ang, sub_index = subgraph\n",
    "            prediction = model(\n",
    "                batch.x.to(device),\n",
    "                batch.edge_index.to(device),\n",
    "                batch.edge_attr.to(device),\n",
    "                batch.batch.to(device),\n",
    "                sub_atom_idx.to(device),\n",
    "                sub_edge_idx.to(device),\n",
    "                sub_edge_ang.to(device),\n",
    "                sub_index.to(device)\n",
    "                    )\n",
    "            target_labels = batch.y.to(device)\n",
    "            difference.append(prediction.cpu().detach().numpy() - target_labels.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.05258322], dtype=float32),\n",
       " array([0.01197743], dtype=float32),\n",
       " array([0.02231145], dtype=float32),\n",
       " array([-0.00471711], dtype=float32),\n",
       " array([0.03448701], dtype=float32),\n",
       " array([0.01677513], dtype=float32),\n",
       " array([0.02334952], dtype=float32),\n",
       " array([0.00833178], dtype=float32),\n",
       " array([0.04031897], dtype=float32),\n",
       " array([0.02786326], dtype=float32),\n",
       " array([0.04365063], dtype=float32),\n",
       " array([0.04260755], dtype=float32),\n",
       " array([-0.00717854], dtype=float32),\n",
       " array([0.00841928], dtype=float32),\n",
       " array([0.01402354], dtype=float32),\n",
       " array([0.04476237], dtype=float32),\n",
       " array([0.02186656], dtype=float32),\n",
       " array([-0.00053573], dtype=float32),\n",
       " array([0.02552938], dtype=float32),\n",
       " array([0.01608419], dtype=float32),\n",
       " array([0.00823307], dtype=float32),\n",
       " array([-0.01647043], dtype=float32),\n",
       " array([0.01133657], dtype=float32),\n",
       " array([[-3.6234312, -3.6234312, -3.6234312, ..., -3.6234312, -3.6234312, -3.6234312],\n",
       "        [-3.6234312, -3.6234312, -3.6234312, ..., -3.6234312, -3.6234312, -3.6234312],\n",
       "        [-3.6234312, -3.6234312, -3.6234312, ..., -3.6234312, -3.6234312, -3.6234312],\n",
       "        ...,\n",
       "        [-3.6234312, -3.6234312, -3.6234312, ..., -3.6234312, -3.6234312, -3.6234312],\n",
       "        [-3.6234312, -3.6234312, -3.6234312, ..., -3.6234312, -3.6234312, -3.6234312],\n",
       "        [-3.6234312, -3.6234312, -3.6234312, ..., -3.6234312, -3.6234312, -3.6234312]], dtype=float32),\n",
       " array([0.01525354], dtype=float32),\n",
       " array([0.05401134], dtype=float32),\n",
       " array([0.02481461], dtype=float32),\n",
       " array([-0.00496125], dtype=float32),\n",
       " array([-0.00917816], dtype=float32),\n",
       " array([0.00799966], dtype=float32),\n",
       " array([0.0282588], dtype=float32),\n",
       " array([0.03594089], dtype=float32),\n",
       " array([0.04316092], dtype=float32),\n",
       " array([0.01153111], dtype=float32),\n",
       " array([0.02936697], dtype=float32),\n",
       " array([0.00545955], dtype=float32),\n",
       " array([0.00462174], dtype=float32),\n",
       " array([0.00915623], dtype=float32),\n",
       " array([0.02977967], dtype=float32),\n",
       " array([0.02502489], dtype=float32),\n",
       " array([0.01259041], dtype=float32),\n",
       " array([0.00738406], dtype=float32),\n",
       " array([0.04781723], dtype=float32),\n",
       " array([0.02360082], dtype=float32),\n",
       " array([0.05468893], dtype=float32),\n",
       " array([0.01115942], dtype=float32),\n",
       " array([0.02312088], dtype=float32),\n",
       " array([0.02984357], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minideeph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
